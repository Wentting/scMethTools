{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1dde4c-8274-4ad5-81bd-0bd623e8c72a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'snapatac2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscMethtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocessing \u001b[38;5;28;01mas\u001b[39;00m pp\n",
      "File \u001b[1;32mD:\\Test\\scMethTools\\scMethtools\\preprocessing\\__init__.py:9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/python3\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m> Author: zongwt \u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m> Created Time: 2023年08月21日\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuild_mtx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mD:\\Test\\scMethTools\\scMethtools\\preprocessing\\build_mtx.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_genome\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Genome\n\u001b[0;32m     26\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimport_bed_file\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconvert_coo_file_to_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_files_with_suffix\u001b[39m(path, suffix):\n",
      "File \u001b[1;32mD:\\Test\\scMethTools\\scMethtools\\_genome.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/python3\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m> Author: zongwt \u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m> Created Time: 2023年08月21日\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnapatac2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpooch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Decompress\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGenome\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'snapatac2'"
     ]
    }
   ],
   "source": [
    "from scMethtools import preprocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fac2fac-f3e7-4095-885a-d5f9af34eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.import_bed_file(\n",
    "    data_dir ='D:\\\\Test/GSE56789/raw/',\n",
    "    output_dir = 'D:\\\\Test/GSE56789/temp/',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "907e105e-62df-41e2-8fb2-9d4910684761",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Genome:\n",
    "    def __init__(self, chrom_sizes, annotation_filename, fasta = None) -> None:\n",
    "        self.chrom_sizes = chrom_sizes\n",
    "        self._annotation_filename = annotation_filename\n",
    "        self._fasta_filename = fasta\n",
    "\n",
    "    def fetch_annotations(self):\n",
    "        return datasets().fetch(self._annotation_filename)\n",
    "\n",
    "    def fetch_fasta(self):\n",
    "        return datasets().fetch(self._fasta_filename, processor = Decompress(method = \"gzip\"))\n",
    "GRCh38 = Genome(\n",
    "    {\n",
    "        \"chr1\": 248956422,\n",
    "        \"chr2\": 242193529,\n",
    "        \"chr3\": 198295559,\n",
    "        \"chr4\": 190214555,\n",
    "        \"chr5\": 181538259,\n",
    "        \"chr6\": 170805979,\n",
    "        \"chr7\": 159345973,\n",
    "        \"chr8\": 145138636,\n",
    "        \"chr9\": 138394717,\n",
    "        \"chr10\": 133797422,\n",
    "        \"chr11\": 135086622,\n",
    "        \"chr12\": 133275309,\n",
    "        \"chr13\": 114364328,\n",
    "        \"chr14\": 107043718,\n",
    "        \"chr15\": 101991189,\n",
    "        \"chr16\": 90338345,\n",
    "        \"chr17\": 83257441,\n",
    "        \"chr18\": 80373285,\n",
    "        \"chr19\": 58617616,\n",
    "        \"chr20\": 64444167,\n",
    "        \"chr21\": 46709983,\n",
    "        \"chr22\": 50818468,\n",
    "        \"chrX\": 156040895,\n",
    "        \"chrY\": 57227415\n",
    "    },\n",
    "    \"gencode_v41_GRCh38.gff3.gz\",\n",
    "    \"gencode_v41_GRCh38.fa.gz\",\n",
    ")\n",
    "\n",
    "hg38 = GRCh38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "756b3e3a-dcb5-4320-b0a6-00e74725e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom_size_dict = hg38.chrom_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "198f272b-6024-476d-8da0-d45ba5bf2154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chr1': 248956422,\n",
       " 'chr2': 242193529,\n",
       " 'chr3': 198295559,\n",
       " 'chr4': 190214555,\n",
       " 'chr5': 181538259,\n",
       " 'chr6': 170805979,\n",
       " 'chr7': 159345973,\n",
       " 'chr8': 145138636,\n",
       " 'chr9': 138394717,\n",
       " 'chr10': 133797422,\n",
       " 'chr11': 135086622,\n",
       " 'chr12': 133275309,\n",
       " 'chr13': 114364328,\n",
       " 'chr14': 107043718,\n",
       " 'chr15': 101991189,\n",
       " 'chr16': 90338345,\n",
       " 'chr17': 83257441,\n",
       " 'chr18': 80373285,\n",
       " 'chr19': 58617616,\n",
       " 'chr20': 64444167,\n",
       " 'chr21': 46709983,\n",
       " 'chr22': 50818468,\n",
       " 'chrX': 156040895,\n",
       " 'chrY': 57227415}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrom_size_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd5fd5cf-9cfd-49af-bc4f-3b21daab9819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 20 40 60 80] [ 50  70  90 110 130]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "bin_start = np.array(list(range(0, 100, 20)))\n",
    "bin_end = bin_start + 50\n",
    "print(bin_start,bin_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94db9e70-14ad-4227-b0e9-97a0b35d5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "from pathlib import Path\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy import sparse\n",
    "import datetime as datetime\n",
    "from typing_extensions import Literal\n",
    "from typing import Union\n",
    "import anndata as ad\n",
    "import subprocess\n",
    "import pathlib\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6125914-e852-4c4e-b3ab-2e8593010d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sliding_windows_with_step_size(window_size,step_size,ref,chrom_size = None,chrom_file = None):\n",
    "    \"\"\"\n",
    "\n",
    "    :param window_size:\n",
    "    :param step_size:\n",
    "    :param ref:\n",
    "        A Genome object, providing gene annotation and chromosome sizes.\n",
    "        If not set, `gff_file` and `chrom_size` must be provided.\n",
    "        `genome` has lower priority than `gff_file` and `chrom_size`.\n",
    "    :param chrom_file:\n",
    "        File name of the gene annotation file in BED or GFF or GTF format.\n",
    "        This is required if `ref` is not set.\n",
    "        Setting `chrom_file` will override the annotations from the `genome` parameter.\n",
    "    :param chrom_size:\n",
    "        A dictionary containing chromosome sizes, for example,\n",
    "        `{\"chr1\": 2393, \"chr2\": 2344, ...}`.\n",
    "        This is required if `genome` is not set.\n",
    "        Setting `chrom_size` will override the chrom_size from the `genome` parameter.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    chrom_size_dict = {}\n",
    "\n",
    "    if step_size is None:\n",
    "        step_size = window_size\n",
    "    if chrom_file is None:\n",
    "        if ref is not None:\n",
    "            chrom_size_dict = ref.chrom_sizes\n",
    "    else:\n",
    "        chrom_size_dict = _load_chrom_size_file(chrom_file) # user defined reference, especially for other species\n",
    "\n",
    "    records = []\n",
    "    for chrom, chrom_length in chrom_size_dict.items():\n",
    "        bin_start = np.array(list(range(0, chrom_length, step_size)))\n",
    "        bin_end = bin_start + window_size\n",
    "        bin_end[np.where(bin_end > chrom_length)] = chrom_length\n",
    "        chrom_df = pd.DataFrame(dict(start=bin_start, end=bin_end))\n",
    "        chrom_df['chrom'] = chrom\n",
    "        records.append(chrom_df)\n",
    "    total_df = pd.concat(records)[['chrom', 'start', 'end']].reset_index(drop=True)\n",
    "    return total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3eb8d0e-b04b-4417-ac6f-6e0201d0c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coo_to_csr_with_annotation(coo_mat,window_size=100000,step_size=None,feature_file=None):\n",
    "    \"\"\"\n",
    "     for coo_matrix, measure methylation level for given bins or genomic features\n",
    "    :param coo_mat:\n",
    "    :param chrom:\n",
    "    :param window_size:\n",
    "    :param step_size:\n",
    "    :param feature_file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    csr_mat = coo_mat.tocsr()\n",
    "    n_cells = csr_mat.shape[1]\n",
    "    # # 找到所有非空行的索引\n",
    "    # non_empty_rows = np.unique(csr_mat.nonzero()[0])\n",
    "    # # 从CSR矩阵中提取这些行的数据，创建一个新的矩阵\n",
    "    # dense = csr_mat[non_empty_rows].todense()\n",
    "    # chunk = pd.read_csv('D://Test/GSE56789/temp/chrY_chunk0000000.coo', delimiter=\",\", header=None).values\n",
    "    # sorting_idx = np.lexsort((chunk[:, 1], chunk[:, 0]))\n",
    "    # chunk[sorting_idx, 0]\n",
    "    # data = (chunk[sorting_idx, 2] + 1).astype(int)\n",
    "    # row = sorting_idx.astype(int)\n",
    "    # col = chunk[sorting_idx, 1].astype(int)\n",
    "    # coo_new = sparse.coo_matrix((data, (row, col)))\n",
    "    # csr_new = coo_new.tocsr()\n",
    "    feature_mtx = {}\n",
    "    if feature_file is not None:\n",
    "        for bed_entries in _load_feature(feature_file):\n",
    "            chr, start, end, others = bed_entries\n",
    "            mean = caculate_methylation_feature(csr_mat, start, end, n_cells)\n",
    "            feature_name = '_'.join([chr, str(start), str(end)])\n",
    "            feature_mtx[feature_name] = mean\n",
    "    elif window_size !=0:\n",
    "        feature_entries = _sliding_windows_with_step_size(window_size,step_size,ref=hg38)\n",
    "        # 遍历每一行\n",
    "        for index, row in feature_entries.iterrows():\n",
    "            chr = row['chrom']\n",
    "            start = row['start']\n",
    "            end = row['end']\n",
    "            mean = caculate_methylation_feature(csr_mat, start, end, n_cells)\n",
    "            feature_name = f\"{chr}_{start}_{end}\"\n",
    "            feature_mtx[feature_name] = mean\n",
    "    return feature_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d370cb4-d007-4950-a03c-152f86ab786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coo_to_csr_with_annotation1(chrom,window_size=100000,step_size=None,feature_file=None):\n",
    "    \"\"\"\n",
    "     for coo_matrix, measure methylation level for given bins or genomic features\n",
    "    :param coo_mat:\n",
    "    :param chrom:\n",
    "    :param window_size:\n",
    "    :param step_size:\n",
    "    :param feature_file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    temp_dir = Path('D://Test/GSE56789/out/')\n",
    "    matrix = sparse.vstack([sparse.load_npz(path) for path in temp_dir.glob('*npz')])\n",
    "    csr_mat = coo_mat.tocsr()\n",
    "    n_cells = csr_mat.shape[1]\n",
    "    # # 找到所有非空行的索引\n",
    "    # non_empty_rows = np.unique(csr_mat.nonzero()[0])\n",
    "    # # 从CSR矩阵中提取这些行的数据，创建一个新的矩阵\n",
    "    # dense = csr_mat[non_empty_rows].todense()\n",
    "    # chunk = pd.read_csv('D://Test/GSE56789/temp/chrY_chunk0000000.coo', delimiter=\",\", header=None).values\n",
    "    # sorting_idx = np.lexsort((chunk[:, 1], chunk[:, 0]))\n",
    "    # chunk[sorting_idx, 0]\n",
    "    # data = (chunk[sorting_idx, 2] + 1).astype(int)\n",
    "    # row = sorting_idx.astype(int)\n",
    "    # col = chunk[sorting_idx, 1].astype(int)\n",
    "    # coo_new = sparse.coo_matrix((data, (row, col)))\n",
    "    # csr_new = coo_new.tocsr()\n",
    "    feature_mtx = {}\n",
    "    if feature_file is not None:\n",
    "        for bed_entries in _load_feature(feature_file):\n",
    "            chr, start, end, others = bed_entries\n",
    "            mean = caculate_methylation_feature(csr_mat, start, end, n_cells)\n",
    "            feature_name = '_'.join([chr, str(start), str(end)])\n",
    "            feature_mtx[feature_name] = mean\n",
    "    elif window_size !=0:\n",
    "        feature_entries = _sliding_windows_with_step_size(window_size,step_size,ref=hg38)\n",
    "        # 遍历每一行\n",
    "        for index, row in feature_entries.iterrows():\n",
    "            chr = row['chrom']\n",
    "            start = row['start']\n",
    "            end = row['end']\n",
    "            mean = caculate_methylation_feature(csr_mat, start, end, n_cells)\n",
    "            feature_name = f\"{chr}_{start}_{end}\"\n",
    "            feature_mtx[feature_name] = mean\n",
    "    return feature_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7af65d2-afce-40be-8341-b6850a788e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_methylation_feature(csr_mat,start,end,n_cells,min_cov=0):\n",
    "    mean_array = np.zeros(n_cells)\n",
    "    # 计算每列的平均值\n",
    "    mean_list = []\n",
    "    for col_idx in range(csr_mat.shape[1]):\n",
    "        col_data = csr_mat[start-1:end, col_idx].toarray()\n",
    "        col_data = col_data[col_data != 0]# 跳过值为0的数据\n",
    "        col_data[col_data == -1] = 0# 在计算的时候把-1当成0计算\n",
    "        if col_data.size == 0:\n",
    "            mean_array[col_idx] = np.nan\n",
    "        if col_data.size < min_cov:\n",
    "            mean_array[col_idx] = np.nan #如果一个feature覆盖的细胞数量少于多少就删除\n",
    "        else:\n",
    "            mean_array[col_idx] = np.mean(col_data)\n",
    "    return mean_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04976483-276b-45db-8669-37836c3e1aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<195371432x52 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13623863 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dir = temp_dir = Path('D://Test/GSE56789/out/')\n",
    "matrix = sparse.vstack([sparse.load_npz(path) for path in temp_dir.glob('*npz')])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aafde3a-01b7-41a5-82d3-3dc35548384a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\envs\\py39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "D:\\conda\\envs\\py39\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_matrix = convert_coo_to_csr_with_annotation(matrix)\n",
    "df = pd.DataFrame.from_dict(feature_matrix) #这一步很慢\n",
    "#默认10000的bins，大概有三万的特征\n",
    "#能不能先分染色体然后再合并矩阵\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9765b8a-137f-4053-b7df-7463cad07cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import click\n",
    "def echo(*args, **kwargs):\n",
    "    click.echo(*args, **kwargs, err=True)\n",
    "    return\n",
    "def secho(*args, **kwargs):\n",
    "    click.secho(*args, **kwargs, err=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea19a149-1654-4dd3-991b-715abfbd4851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_feature(feature_file,chrom,file_format = None):\n",
    "    if file_format is None:\n",
    "        file_format = feature_file[-3:]\n",
    "    if file_format not in ['bed','txt','gtf','gff']:\n",
    "        print (f\"not support {file_format}  format right now, please check your file again\")\n",
    "    # need specify gtf gff loading method\n",
    "    else:\n",
    "        features_chrom = []\n",
    "        with open(feature_file) as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\"#\"):\n",
    "                    continue\n",
    "                value = line.strip().split(\"\\t\")\n",
    "                chrom_df = pd.DataFrame(dict(start=value[0], end=value[1],identity=value[3:]))\n",
    "                chrom_df['chrom'] = value[0]\n",
    "\n",
    "# 定义一个函数，用于处理染色体上的注释\n",
    "def process_chromosome(path,chrom_data):\n",
    "    chrom, chrom_records = chrom_data\n",
    "    # 读取染色体对应的文件，假设文件名为 chrom_filename\n",
    "    #for coo_path in sorted(glob(os.path.join(temp_dir, \"chr1*.npz\"))):\n",
    "    temp_dir = \n",
    "    matrix =  sparse.vstack([sparse.load_npz(path) for path in temp_dir.glob(f'{chrom}*npz')])\n",
    "    secho(f\"\\n merge {chrom} coo_matrix and bin it\", fg=\"green\")\n",
    "    # 遍历每一行\n",
    "    for index, row in feature_entries.iterrows():\n",
    "        chr = row['chrom']\n",
    "        start = row['start']\n",
    "        end = row['end']\n",
    "        mean = caculate_methylation_feature(csr_mat, start, end, n_cells)\n",
    "        feature_name = f\"{chr}_{start}_{end}\"\n",
    "        feature_mtx[feature_name] = mean\n",
    "    return feature_mtx\n",
    "\n",
    "\n",
    "\n",
    "#for coo_path in sorted(glob(os.path.join(temp_dir, \"chr1*.npz\"))):\n",
    "matrix =  sparse.vstack([sparse.load_npz(path) for path in temp_dir.glob('chr1*npz')])\n",
    "secho(f\"\\n merge {chrom} coo_matrix and bin it\", fg=\"green\")\n",
    "#注释文件单独拿出来\n",
    "\n",
    "if feature_file is not None:\n",
    "    feature = _load_feature(feature_file)\n",
    "elif window_size !=0: #defined reference from scMethools\n",
    "    feature = _sliding_windows_with_step_size(window_size,step_size,ref=Genome.hg38)\n",
    "# cauculate methylation level for bins in parallel with all chromosome\n",
    "\n",
    "chrom_data = [(chrom, feature[feature['chrom'] == chrom]) for chrom in feature['chrom'].unique()]\n",
    "pool = multiprocessing.Pool(processes=min(cpu,len(chrom_data)))\n",
    "# 将染色体数据分组传递给处理函数\n",
    "results = pool.map(process_chromosome, chrom_data)\n",
    "# 将处理结果合并成一个 DataFrame\n",
    "result_df = pd.concat([pd.DataFrame.from_dict(r) for r in results], ignore_index=True)\n",
    "print(result_df)\n",
    "# 关闭线程池\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "df = pd.DataFrame.from_dict(feature_matrix) #这一步很慢\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177b5340-5c0e-47ea-9d3c-eac5542d2bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chrom,size in chrom_sizes.items():\n",
    "    pool.apply_async(convert_coo_to_csr_with_annotation,args=(chr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfdb32c0-f844-4c87-8fd3-fadfdf1ce911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数，用于处理染色体上的注释\n",
    "def process_chromosome(path,chrom_data):\n",
    "    chrom, chrom_records = chrom_data\n",
    "    secho(f\"\\n merge {chrom} coo_matrix and bin it\", fg=\"green\")\n",
    "    # 读取染色体对应的文件，假设文件名为 chrom_filename\n",
    "    #for coo_path in sorted(glob(os.path.join(temp_dir, \"chr1*.npz\"))):\n",
    "    matrix =  sparse.vstack([sparse.load_npz(path) for path in temp_dir.glob(f'{chrom}*npz')])\n",
    "    # 遍历每一行\n",
    "    for index, row in feature_entries.iterrows():\n",
    "        chr = row['chrom']\n",
    "        start = row['start']\n",
    "        end = row['end']\n",
    "        mean = caculate_methylation_feature(csr_mat, start, end, n_cells)\n",
    "        feature_name = f\"{chr}_{start}_{end}\"\n",
    "        feature_mtx[feature_name] = mean\n",
    "    return feature_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b54fc50-3b14-4275-98c7-90b4ad375641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "from pathlib import Path\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy import sparse\n",
    "import datetime as datetime\n",
    "from typing_extensions import Literal\n",
    "from typing import Union\n",
    "import anndata as ad\n",
    "import subprocess\n",
    "import pathlib\n",
    "import collections\n",
    "class Genome:\n",
    "    def __init__(self, chrom_sizes, annotation_filename, fasta = None) -> None:\n",
    "        self.chrom_sizes = chrom_sizes\n",
    "        self._annotation_filename = annotation_filename\n",
    "        self._fasta_filename = fasta\n",
    "\n",
    "    def fetch_annotations(self):\n",
    "        return datasets().fetch(self._annotation_filename)\n",
    "\n",
    "    def fetch_fasta(self):\n",
    "        return datasets().fetch(self._fasta_filename, processor = Decompress(method = \"gzip\"))\n",
    "# 定义一个函数，用于处理染色体上的注释\n",
    "def process_chromosome(temp_dir,chrom_data):\n",
    "    chrom, chrom_records = chrom_data\n",
    "    secho(f\"\\n merge {chrom} coo_matrix and bin it \", fg=\"green\")\n",
    "    #for coo_path in sorted(glob(os.path.join(temp_dir, \"chr1*.npz\"))):\n",
    "    temp_dir = Path('D://Test/GSE56789/out/')\n",
    "    coo_mat =  sparse.vstack([sparse.load_npz(path) for path in temp_dir.glob(f'{chrom}*npz')])\n",
    "    coo_mat.data = np.where(coo_mat.data == 0, -1, coo_mat.data) # change all zero to -1 which means unmethylated for calculating\n",
    "    csr_mat = coo_mat.tocsr()\n",
    "    n_cells = csr_mat.shape[1]\n",
    "    secho(f\"\\n merge {chrom} coo_matrix and bin it for {n_cells} cell \", fg=\"green\")\n",
    "    # 遍历每一行\n",
    "    feature_mtx = {}\n",
    "    for index, row in chrom_records.iterrows():\n",
    "        chr = row['chrom']\n",
    "        start = row['start']\n",
    "        end = row['end']\n",
    "        mean = caculate_methylation_feature(csr_mat, start, end, n_cells)\n",
    "        feature_name = f\"{chr}_{start}_{end}\"\n",
    "        feature_mtx[feature_name] = mean\n",
    "    return feature_mtx\n",
    "import click\n",
    "def echo(*args, **kwargs):\n",
    "    click.echo(*args, **kwargs, err=True)\n",
    "    return\n",
    "def secho(*args, **kwargs):\n",
    "    click.secho(*args, **kwargs, err=True)\n",
    "    return\n",
    "def caculate_methylation_feature(csr_mat,start,end,n_cells,min_cov=0):\n",
    "    mean_array = np.zeros(n_cells)\n",
    "    # 计算每列的平均值\n",
    "    mean_list = []\n",
    "    for col_idx in range(csr_mat.shape[1]):\n",
    "        col_data = csr_mat[start-1:end, col_idx].toarray()\n",
    "        #col_data = col_data[col_data != 0]# 跳过值为0的数据\n",
    "        #col_data[col_data == -1] = 0# 在计算的时候把-1当成0计算\n",
    "        if col_data.size == 0 or col_data.size < min_cov:\n",
    "            mean_array[col_idx] = np.nan\n",
    "        else:\n",
    "            mean_array[col_idx] = np.mean(col_data)\n",
    "    return mean_array\n",
    "def _sliding_windows_with_step_size(window_size,step_size,ref,chrom_size = None,chrom_file = None):\n",
    "    \"\"\"\n",
    "\n",
    "    :param window_size:\n",
    "    :param step_size:\n",
    "    :param ref:\n",
    "        A Genome object, providing gene annotation and chromosome sizes.\n",
    "        If not set, `gff_file` and `chrom_size` must be provided.\n",
    "        `genome` has lower priority than `gff_file` and `chrom_size`.\n",
    "    :param chrom_file:\n",
    "        File name of the gene annotation file in BED or GFF or GTF format.\n",
    "        This is required if `ref` is not set.\n",
    "        Setting `chrom_file` will override the annotations from the `genome` parameter.\n",
    "    :param chrom_size:\n",
    "        A dictionary containing chromosome sizes, for example,\n",
    "        `{\"chr1\": 2393, \"chr2\": 2344, ...}`.\n",
    "        This is required if `genome` is not set.\n",
    "        Setting `chrom_size` will override the chrom_size from the `genome` parameter.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    chrom_size_dict = {}\n",
    "\n",
    "    if step_size is None:\n",
    "        step_size = window_size\n",
    "    if chrom_file is None:\n",
    "        if ref is not None:\n",
    "            chrom_size_dict = ref.chrom_sizes\n",
    "    else:\n",
    "        chrom_size_dict = _load_chrom_size_file(chrom_file) # user defined reference, especially for other species\n",
    "\n",
    "    records = []\n",
    "    for chrom, chrom_length in chrom_size_dict.items():\n",
    "        bin_start = np.array(list(range(0, chrom_length, step_size)))\n",
    "        bin_end = bin_start + window_size\n",
    "        bin_end[np.where(bin_end > chrom_length)] = chrom_length\n",
    "        chrom_df = pd.DataFrame(dict(start=bin_start, end=bin_end))\n",
    "        chrom_df['chrom'] = chrom\n",
    "        records.append(chrom_df)\n",
    "    total_df = pd.concat(records)[['chrom', 'start', 'end']].reset_index(drop=True)\n",
    "    return total_df\n",
    "\n",
    "\n",
    "def main():\n",
    "    GRCh38 = Genome(\n",
    "    {\n",
    "        \"chr1\": 248956422,\n",
    "        \"chr2\": 242193529,\n",
    "        \"chr3\": 198295559,\n",
    "        \"chr4\": 190214555,\n",
    "        \"chr5\": 181538259,\n",
    "        \"chr6\": 170805979,\n",
    "        \"chr7\": 159345973,\n",
    "        \"chr8\": 145138636,\n",
    "        \"chr9\": 138394717,\n",
    "        \"chr10\": 133797422,\n",
    "        \"chr11\": 135086622,\n",
    "        \"chr12\": 133275309,\n",
    "        \"chr13\": 114364328,\n",
    "        \"chr14\": 107043718,\n",
    "        \"chr15\": 101991189,\n",
    "        \"chr16\": 90338345,\n",
    "        \"chr17\": 83257441,\n",
    "        \"chr18\": 80373285,\n",
    "        \"chr19\": 58617616,\n",
    "        \"chr20\": 64444167,\n",
    "        \"chr21\": 46709983,\n",
    "        \"chr22\": 50818468,\n",
    "        \"chrX\": 156040895,\n",
    "        \"chrY\": 57227415\n",
    "    },\n",
    "    \"gencode_v41_GRCh38.gff3.gz\",\n",
    "    \"gencode_v41_GRCh38.fa.gz\",\n",
    "    )\n",
    "    hg38 = GRCh38\n",
    "    cpu = 15\n",
    "    feature = _sliding_windows_with_step_size(100000,100000,ref=hg38)\n",
    "    #all chromosome or defined chromosome\n",
    "    chrom_data = [(chrom, feature[feature['chrom'] == chrom]) for chrom in feature['chrom'].unique()]\n",
    "    pool = mp.Pool(processes=min(cpu,len(chrom_data)))\n",
    "    # 将染色体数据分组传递给处理函数\n",
    "    results = []\n",
    "    print(\"开始执行主程序\")\n",
    "    start_time=time.time()\n",
    "    for i in range(len(chrom_data)):\n",
    "        chrom = chrom_data[i]\n",
    "        results.append(pool.apply_async(process_chromosome, args=('D://Test/GSE56789/out/',chrom)))\n",
    "    # with Pool(processes=2) as pool:\n",
    "    #     # 使用 map 方法并行处理 chrom_data 中的每个元素，固定参数为 fixed_arg\n",
    "    #     partial_process_chromosome = partial(process_chromosome, 'D://Test/GSE56789/out/')\n",
    "    #     results = pool.map(partial_process_chromosome, chrom_data)\n",
    "    \n",
    "    # 将处理结果合并成一个 DataFrame\n",
    "    result_df = pd.concat([pd.DataFrame.from_dict(r) for r in results], ignore_index=True)\n",
    "    print(result_df)\n",
    "    # 关闭线程池\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print(\"开始执行子进程\")\n",
    "    print(\"主进程结束耗时%s\"%(time.time()-start_time))\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c8236-1566-4276-b9a7-95d92a0f77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#every single paraller for one chromosome\n",
    "feature_mtx = process_chromosome('D://Test/GSE56789/out/',chrom_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264865d5-8543-4e39-b369-2b3f12276e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_data = anndata.read(\"D://Test/scMeTools/test_anndata.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a60f79-eaa3-42d2-bd66-9667db65ff78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
